import { App, Plugin, PluginSettingTab, Setting, TFile, Notice } from "obsidian";
import { requestUrl } from "obsidian";

// =============== SETTINGS ==================

interface ImageToTextSettings {
	openaiApiKey: string;
	model: string;
}

const DEFAULT_SETTINGS: ImageToTextSettings = {
	openaiApiKey: "",
	model: "gpt-4o-mini"
};

// =============== MAIN PLUGIN CLASS ==================

export default class ImageToTextPlugin extends Plugin {
	settings: ImageToTextSettings = DEFAULT_SETTINGS;

	async onload() {
		console.debug("‚úÖ ImageToTextPlugin loaded");

		await this.loadSettings();
		this.addSettingTab(new ImageToTextSettingTab(this.app, this));

		// –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
		this.registerEvent(
			this.app.vault.on("create", async (file: TFile) => {
				if (file.extension.match(/(png|jpg|jpeg|webp)/i)) {
					new Notice(`üñº Processing ${file.name}...`);

					// –ñ–¥—ë–º –Ω–µ–º–Ω–æ–≥–æ, —á—Ç–æ–±—ã Obsidian —É—Å–ø–µ–ª —Å–æ–∑–¥–∞—Ç—å –∑–∞–º–µ—Ç–∫—É
					await new Promise(resolve => setTimeout(resolve, 1000));

					await this.processImage(file);
				}
			})
		);
	}

	onunload() {
		console.debug("üõë ImageToTextPlugin unloaded");
	}

	async loadSettings() {
		this.settings = Object.assign({}, DEFAULT_SETTINGS, await this.loadData());
	}

	async saveSettings() {
		await this.saveData(this.settings);
	}

	// =============== IMAGE PROCESSING ==================

	extractJsonFromText(text: string): string | null {
		if (!text || typeof text !== "string") return null;

		text = text.replace(/^\uFEFF/, "").trim();

		const fenceRegex = /```(?:json)?\s*([\s\S]*?)\s*```/i;
		const fenceMatch = text.match(fenceRegex);
		if (fenceMatch && fenceMatch[1]) {
			return fenceMatch[1].trim();
		}

		const firstBrace = text.indexOf("{");
		const lastBrace = text.lastIndexOf("}");
		if (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {
			return text.slice(firstBrace, lastBrace + 1).trim();
		}

		return text.trim() || null;
	}

	tryParseJson(text: string) {
		const candidate = this.extractJsonFromText(text);
		if (!candidate) throw new Error("No JSON found in response text");

		const cleaned = candidate
			.replace(/^\u200B/g, "")
			.replace(/\u00A0/g, " ")
			.trim();

		try {
			return JSON.parse(cleaned);
		} catch (err) {
			const e = new Error("JSON.parse failed: " + (err as Error).message);
			throw e;
		}
	}

	sanitizeFileName(name: string): string {
		return name.replace(/[\\/:"*?<>|]+/g, "").trim() || "contact";
	}

	async findNoteWithImage(imageFile: TFile): Promise<TFile | null> {
		const embed = `![[${imageFile.name}]]`;
		const markdownFiles = this.app.vault.getMarkdownFiles();

		console.debug(`markdownFiles:`, markdownFiles);

		for (const mdFile of markdownFiles) {
			console.debug(`check md:`, mdFile.name);
			try {
				const content = await this.app.vault.read(mdFile);
				if (content.includes(embed)) {
					console.debug(`‚úÖ Found note with image: ${mdFile.name}`);
					return mdFile;
				}
			} catch (error) {
				console.error(`Error reading ${mdFile.name}:`, error);
			}
		}

		console.debug(`‚ùå No note found with embed: ${embed}`);
		return null;
	}

	// –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–æ–¥ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è MIME-—Ç–∏–ø–∞
	getMimeType(file: TFile): string {
		const ext = file.extension.toLowerCase();
		switch (ext) {
			case 'jpg':
			case 'jpeg':
				return 'image/jpeg';
			case 'png':
				return 'image/png';
			case 'gif':
				return 'image/gif';
			case 'webp':
				return 'image/webp';
			case 'bmp':
				return 'image/bmp';
			default:
				return 'image/jpeg';
		}
	}

	async processImage(file: TFile) {
		try {
			const originalBuffer = await this.app.vault.readBinary(file);
			const mimeType = this.getMimeType(file);

			const { rotation, buffer } = await detectBestRotation(
				originalBuffer,
				mimeType,
				this.settings.openaiApiKey
			);

			new Notice(`üß≠ Image rotation detected: ${rotation}¬∞`);

			const base64 = arrayBufferToBase64(buffer);

			// –°–æ–∑–¥–∞—ë–º data URL
			const dataUrl = `data:${mimeType};base64,${base64}`;

			// –í—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ base64 –≤ markdown
			const imageEmbed = `![${file.basename}](${dataUrl})`;

			if (!this.settings.openaiApiKey) {
				new Notice("Please set your openai api key in the plugin settings.");
				return;
			}

			new Notice(`üì§ Sending ${file.name} to OpenAI...`);

			// –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ OpenAI
			const payload = {
				model: "gpt-4o-mini",
				messages: [
					{
						role: "user",
						content: [
							{
								type: "text",
								text:
									"–†–∞—Å–ø–æ–∑–Ω–∞–π —Ç–µ–∫—Å—Ç –≤–∏–∑–∏—Ç–∫–∏ –∏ –≤–µ—Ä–Ω–∏ —Å—Ç—Ä–æ–≥–æ JSON —Ñ–æ—Ä–º–∞—Ç–∞:\n\n" +
									"{\n" +
									'  "name": "",\n' +
									'  "company": "",\n' +
									'  "position": "",\n' +
									'  "phones": [],\n' +
									'  "emails": [],\n' +
									'  "website": "",\n' +
									'  "address": "",\n' +
									'  "rawText": "",\n' +
									"}\n\n" +
									"–ó–∞–ø–æ–ª–Ω–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω–æ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É –≤–∏–∑–∏—Ç–∫–∏."
							},
							{
								type: "image_url",
								image_url: {
									url: `data:image/jpeg;base64,${base64}`
								}
							}
						]
					}
				]
			};

			// const response = await fetch("https://api.openai.com/v1/chat/completions", {
			// 	method: "POST",
			// 	headers: {
			// 		"Content-Type": "application/json",
			// 		"Authorization": `Bearer ${this.settings.openaiApiKey}`
			// 	},
			// 	body: JSON.stringify(payload)
			// });

			// if (!response.ok) {
			// 	const errorText = await response.text();
			// 	throw new Error(`Openai api error: ${response.status} ${errorText}`);
			// }

			// const data = await response.json();

			// use requestUrl from obsidian API instead of fetch
			const response = await requestUrl({
				url: "https://api.openai.com/v1/chat/completions",
				method: "POST",
				headers: {
					"Content-Type": "application/json",
					"Authorization": `Bearer ${this.settings.openaiApiKey}`
				},
				body: JSON.stringify(payload)
			});

			if (response.status !== 200) {
				throw new Error(`OpenAI API error: ${response.status} ${response.text}`);
			}

			const data = response.json;
			//

			const content = data?.choices?.[0]?.message?.content ?? "{}";

			const parsed = this.tryParseJson(content);
			const name = parsed.name?.trim() || file.basename || "Unknown Contact";
			const safeName = this.sanitizeFileName(name);
			const imgName = safeName + "." + file.extension;

			new Notice(`‚úÖ Recognized: ${name}`);

			// –ò—â–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∑–∞–º–µ—Ç–∫—É —Å —ç—Ç–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
			// const existingNote = await this.findNoteWithImage(file);

			// –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–∞—Ä—Ç–∏–Ω–∫—É
			await this.app.vault.rename(file, imgName);

			let notePath: string;
			let noteContent: string;

			// –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∑–∞–º–µ—Ç–∫–∏
			noteContent =
				`**–ö–æ–º–ø–∞–Ω–∏—è:** ${parsed.company || "-"}\n` +
				`**–î–æ–ª–∂–Ω–æ—Å—Ç—å:** ${parsed.position || "-"}\n` +
				`**–¢–µ–ª–µ—Ñ–æ–Ω—ã:**\n${parsed.phones?.length ? parsed.phones.map((p: string) => `- ${p}`).join("\n") : "-"}\n` +
				`**Email:**\n${parsed.emails?.length ? parsed.emails.map((e: string) => `- ${e}`).join("\n") : "-"}\n` +
				`**Website:** ${parsed.website || "-"}\n` +
				`**–ê–¥—Ä–µ—Å:** ${parsed.address || "-"}\n\n` +
				`---\n\n` +
				`**–ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –≤–∏–∑–∏—Ç–∫–∏:**\n${parsed.rawText || ""}\n` +
				imageEmbed;

			// –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é –∑–∞–º–µ—Ç–∫—É —Ä—è–¥–æ–º —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
			const folder = file.parent?.path ?? "";
			notePath = `${folder}/${safeName}.md`;

			// –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —Ñ–∞–π–ª —Å —Ç–∞–∫–∏–º –∏–º–µ–Ω–µ–º
			const existingFile = this.app.vault.getAbstractFileByPath(notePath);
			if (existingFile instanceof TFile) {
				// –ï—Å–ª–∏ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –¥–æ–±–∞–≤–ª—è–µ–º –∫ –∏–º–µ–Ω–∏ –Ω–æ–º–µ—Ä
				let counter = 1;
				let newPath = notePath;
				while (this.app.vault.getAbstractFileByPath(newPath)) {
					newPath = `${folder}/${safeName} (${counter}).md`;
					counter++;
				}
				notePath = newPath;
			}

			await this.app.vault.create(notePath, noteContent);
			new Notice(`üìÑ Created new note: ${safeName}`);

			// —É–¥–∞–ª—è–µ–º –∫–∞—Ä—Ç–∏–Ω–∫—É
			await this.app.vault.delete(file);

		} catch (err) {
			console.error("Error processing image:", err);
			new Notice(`‚ùå Error processing ${file.name}: ${err.message}`);
		}
	}

} // class ImageToTextPlugin

// =============== SETTINGS TAB ==================

class ImageToTextSettingTab extends PluginSettingTab {
	plugin: ImageToTextPlugin;

	constructor(app: App, plugin: ImageToTextPlugin) {
		super(app, plugin);
		this.plugin = plugin;
	}

	display(): void {
		const { containerEl } = this;
		containerEl.empty();

		// containerEl.createEl("h2", { text: "Image to text plugin settings" });
		new Setting(containerEl)
			.setName("Image to text plugin settings")
			.setHeading();

		new Setting(containerEl)
			.setName("Openai api key")
			.setDesc("Enter your openai api key (starts with sk-...)")
			.addText((text) =>
				text
					.setPlaceholder("Sk-...")
					.setValue(this.plugin.settings.openaiApiKey)
					.onChange(async (value) => {
						this.plugin.settings.openaiApiKey = value.trim();
						await this.plugin.saveSettings();
					})
			);

		new Setting(containerEl)
			.setName("Model")
			.setDesc("A model that supports images (e.g. gpt-4o-mini or gpt-4o). Default is gpt-4o-mini.")
			.addText((text) =>
				text
					.setPlaceholder("Gpt-4o-mini")
					.setValue(this.plugin.settings.model)
					.onChange(async (value) => {
						this.plugin.settings.model = value.trim() || DEFAULT_SETTINGS.model;
						await this.plugin.saveSettings();
					})
			);
	}
}

// =============== UTILS ==================

function arrayBufferToBase64(buffer: ArrayBuffer): string {
	const bytes = new Uint8Array(buffer);
	const chunkSize = 0x8000;
	let binary = "";
	for (let i = 0; i < bytes.length; i += chunkSize) {
		const chunk = bytes.subarray(i, Math.min(i + chunkSize, bytes.length));
		binary += String.fromCharCode.apply(null, Array.from(chunk));
	}
	return btoa(binary);
}

// –ü–æ–≤–æ—Ä–æ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ –∑–∞–¥–∞–Ω–Ω—ã–π —É–≥–æ–ª
async function rotateArrayBuffer(
	buffer: ArrayBuffer,
	degrees: number,
	mimeType: string
): Promise<ArrayBuffer> {
	const blob = new Blob([buffer], { type: mimeType });
	const img = await createImageBitmap(blob);

	const canvas = document.createElement("canvas");
	const ctx = canvas.getContext("2d");
	if (!ctx) {
		throw new Error("Failed to get 2D canvas context.");
	}

	if (degrees === 90 || degrees === 270) {
		canvas.width = img.height;
		canvas.height = img.width;
	} else {
		canvas.width = img.width;
		canvas.height = img.height;
	}

	ctx.translate(canvas.width / 2, canvas.height / 2);
	ctx.rotate((degrees * Math.PI) / 180);
	ctx.drawImage(img, -img.width / 2, -img.height / 2);

	return new Promise<ArrayBuffer>((resolve, reject) => {
		canvas.toBlob((b) => {
			if (!b) {
				reject(new Error("Failed to create blob from canvas."));
				return;
			}

			b.arrayBuffer().then(resolve).catch(reject);
		}, mimeType, 0.95);
	});

}

// –û—Ü–µ–Ω–∫–∞ —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏ (–º–∏–Ω–∏-–∑–∞–ø—Ä–æ—Å)
async function scoreImageReadability(
	base64: string,
	apiKey: string
): Promise<number> {
	const payload = {
		model: "gpt-4o-mini",
		max_tokens: 10,
		messages: [
			{
				role: "user",
				content: [
					{
						type: "text",
						text:
							"–û—Ü–µ–Ω–∏, –Ω–∞—Å–∫–æ–ª—å–∫–æ —É–¥–æ–±–Ω–æ —á–∏—Ç–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ " +
							"–≤ —Ç–µ–∫—É—â–µ–π –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏.\n" +
							"–û—Ç–≤–µ—Ç—å —Å—Ç—Ä–æ–≥–æ –æ–¥–Ω–∏–º —á–∏—Å–ª–æ–º –æ—Ç 0 –¥–æ 10."
					},
					{
						type: "image_url",
						image_url: {
							url: `data:image/jpeg;base64,${base64}`
						}
					}
				]
			}
		]
	};

	// const response = await fetch("https://api.openai.com/v1/chat/completions", {
	// 	method: "POST",
	// 	headers: {
	// 		"Content-Type": "application/json",
	// 		"Authorization": `Bearer ${apiKey}`
	// 	},
	// 	body: JSON.stringify(payload)
	// });
	// const data = await response.json();

	// use requestUrl from obsidian API instead of fetch
	const response = await requestUrl({
		url: "https://api.openai.com/v1/chat/completions",
		method: "POST",
		headers: {
			"Content-Type": "application/json",
			"Authorization": `Bearer ${apiKey}`
		},
		body: JSON.stringify(payload)
	});

	if (response.status !== 200) {
		throw new Error(`OpenAI API error: ${response.status} ${response.text}`);
	}

	const data = response.json;
	///
	
	const text = data?.choices?.[0]?.message?.content ?? "0";
	const score = parseInt(text, 10);

	return Number.isFinite(score) ? score : 0;
}

// –ü–æ–∏—Å–∫ –ª—É—á—à–µ–≥–æ —É–≥–ª–∞ –ø–æ–≤–æ—Ä–æ—Ç–∞
async function detectBestRotation(
	buffer: ArrayBuffer,
	mimeType: string,
	apiKey: string
): Promise<{ rotation: number; buffer: ArrayBuffer }> {

	const rotations = [0, 90, 180, 270];
	let bestScore = -1;
	let bestRotation = 0;
	let bestBuffer = buffer;

	for (const deg of rotations) {
		const rotatedBuffer =
			deg === 0 ? buffer : await rotateArrayBuffer(buffer, deg, mimeType);

		const base64 = arrayBufferToBase64(rotatedBuffer);
		const score = await scoreImageReadability(base64, apiKey);

		console.debug(`[ROTATION CHECK] ${deg}¬∞ ‚Üí score ${score}`);

		if (score > bestScore) {
			bestScore = score;
			bestRotation = deg;
			bestBuffer = rotatedBuffer;
		}
	}

	return { rotation: bestRotation, buffer: bestBuffer };
}
